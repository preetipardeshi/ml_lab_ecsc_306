import tensorflow as tf
import matplotlib.pyplot as plt

x=tf.constant([8.34,19.31,34.32,42.55],name='a')
y=tf.constant([8.34,19.31,34.32,42.55],name='b')
z=tf.constant(1.0)
eqn=tf.constant("y=mx+c")

pred=tf.constant("Predicted values =")
meanx = tf.constant("Mean of x =")
meany = tf.constant("Mean of y =")
variance = tf.constant("Variance of x =")
covariance = tf.constant("Covariance of x and y =")

m_val=tf.constant("Value of m = ")
c_val=tf.constant("Value of c = ")


# Mean of x and y
mean_x = tf.reduce_mean(x)
mean_y = tf.reduce_mean(y)

   
# x-Mean , y-Mean
vx=tf.Variable(x-mean_x, name='var_x')
vy=tf.Variable(y-mean_y, name='var_y')
l=tf.size(x)
n=tf.subtract(l,1)
n=tf.cast(n,tf.float32)
#(x-mean)sq and sum
vs=tf.square(vx)
sn=tf.reduce_sum(vs)
sm=tf.div(sn,n)

   
#Covariance of x and y
cov=tf.multiply(vx,vy)
cm=tf.reduce_sum(cov)
cv=tf.div(cm,n)


#Calculation of m and c
m=tf.divide(cv,sm)
c=mean_y-(mean_x*m)

#Predicted values of Y
p=tf.multiply(x,m)
pry=tf.add(p,c)    


#calculating root-mean-square-error
rms=tf.sqrt(tf.reduce_mean(tf.squared_difference(y,pry)))
   
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)
 
print(sess.run(eqn))
print(sess.run(meanx),sess.run(mean_x))
print(sess.run(meany),sess.run(mean_y))

print(sess.run(variance),sess.run(sm))
print(sess.run(covariance),sess.run(cv))

print(sess.run(m_val),sess.run(m))
print(sess.run(c_val),sess.run(c))

print(sess.run(pred),sess.run(pry))
print(sess.run(rms))

plt.plot(sess.run(y),sess.run(pry),label='Actual-Predicted')
plt.legend()
plt.show()

----------------------------------------------------------------------------------
#Lab2 assignment 2
import tensorflow as tf

def tf_train(X_train,y_train, batch_size=20,learning_rate=0.5):
    
    # tf Graph Input
    x = tf.placeholder(tf.float32, [None, 1]) 
    y_ = tf.placeholder(tf.float32, [None, 1])

# Set model weights
    W = tf.Variable(tf.random_normal([1,1],stddev=0.1))
    b = tf.Variable(tf.zeros([10]))
    a = tf.sigmoid(tf.matmul(x,W))
    
# Construct model
    pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax
    #cost = tf.reduce_mean(-(y_*tf.log(a)+(1-y_)*tf.log(1-a)))
    #train_step = tf.train.GradientDescentOptimizer(1e-2).minimize(cost)
# Minimize error using cross entropy
    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))
# Gradient Descent
    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)
    sess = tf.InteractiveSession()
    tf.initialize_all_variables().run()
# Initializing the variables
    #init = tf.global_variables_initializer()
    
    for epoch in range(1000):
        idx = np.random.choice(int(X_train,batch_size)
        #_, l = sess.run([train_step,cost],feed_dict={x:X_train[idx], y_:y_train[idx]})
         _, l = sess.run([train_step, cost], feed_dict={x:X_train[idx], y_:y_train[idx]})
        
        if epoch%100 == 0:
            print("Loss: "+str(l))
            
X=[2.7810836,1.465489372,3.396561688,1.38807019,3.06407232,7.627531214,5.332441248,6.922596716,8.675418651,7.673756466]
y=[2.550537003,2.362125076,4.400293529,1.850220317,3.005305973,2.759262235,2.088626775,1.77106367,-0.2420686551,3.508563011]
tf_train(X,y)

---------------------------------------------------------------------------------------------------------------------
import tensorflow as tf
import matplotlib.pyplot as plt


#Learning rate=.3
x1=tf.constant([1.0,2.0,3.0,4.0,5.0],name='f')
x2=tf.constant([3.0,1.0,2.0,4.0,5.0],name='s')
x1 = tf.cast(x1,dtype=tf.float32)
x2 =tf.cast(x2,dtype=tf.float32)

y=tf.constant([0,1,0,0,0],name='o')

epoch=tf.constant(100)
z=tf.constant([20.0,40.0,60.0,80.0,100.0])
lr=0.3
k=0
l=0
tO=0.0
t1=0.0
t2=0.0
tn0=0.0
yhat=0.0
T=epoch/20
i=0
model=tf.global_variables_initializer()
yhat=1.0/(1.0+tf.exp(-tO-(t1*x1[i])-(t2*x2[i])))
yhat = tf.cast(yhat,dtype=tf.float32)
y = tf.cast(y,dtype=tf.float32)
            #error = y[i] - yhat
s0 = tf.reduce_sum(tf.multiply(tf.subtract(yhat,y),x))
tn0 = tf.subtract(t0,tf.multiply(lr,s0))
        
with tf.Session()as sess:
    sess.run(model)
    #output=tf.TensorArray(size=tf.cast(T,tf.int32),dtype=tf.float32)
    #theta=tf.TensorArray(size=3,dtype=tf.float32)
    for j in range(sess.run(epoch)):
        sum_err=0
        for i in range(sess.run(tf.size(x1))):
            yhat=1.0/(1.0+tf.exp(-tO-(t1*x1[i])-(t2*x2[i])))
            yhat = tf.cast(yhat,dtype=tf.float32)
            #error = y[i] - yhat
            #sum_err=sum_err+tf.square(error)
            t0=tn0
            s0 = tf.reduce_sum(tf.multiply(tf.subtract(yhat,y),x))
            tn0 = tf.subtract(t0,tf.multiply(lr,s0))           
            i=i+1
           # theta=theta.write(l*2,t2)
        if(j+1)%20==0:
            print("epoch value:",(j+1))
            print("theta0:",sess.run(tn0))
           # print("theta1:",sess.run(t1))
            #print("theta2:",sess.run(t2))
            #print("error: ",sess.run(sum_err))
            output=output.write(k,yhat)
            k=k+1
    output_final=output.stack()
    
    a=sess.run(output_final)
    plt.plot(sess.run(z),a,label='epoch-cost')
    plt.legend()
    plt.show()

