import tensorflow as tf
import matplotlib.pyplot as plt

x=tf.constant([8.34,19.31,34.32,42.55],name='a')
y=tf.constant([8.34,19.31,34.32,42.55],name='b')
z=tf.constant(1.0)
eqn=tf.constant("y=mx+c")

pred=tf.constant("Predicted values =")
meanx = tf.constant("Mean of x =")
meany = tf.constant("Mean of y =")
variance = tf.constant("Variance of x =")
covariance = tf.constant("Covariance of x and y =")

m_val=tf.constant("Value of m = ")
c_val=tf.constant("Value of c = ")


# Mean of x and y
mean_x = tf.reduce_mean(x)
mean_y = tf.reduce_mean(y)

   
# x-Mean , y-Mean
vx=tf.Variable(x-mean_x, name='var_x')
vy=tf.Variable(y-mean_y, name='var_y')
l=tf.size(x)
n=tf.subtract(l,1)
n=tf.cast(n,tf.float32)
#(x-mean)sq and sum
vs=tf.square(vx)
sn=tf.reduce_sum(vs)
sm=tf.div(sn,n)

   
#Covariance of x and y
cov=tf.multiply(vx,vy)
cm=tf.reduce_sum(cov)
cv=tf.div(cm,n)


#Calculation of m and c
m=tf.divide(cv,sm)
c=mean_y-(mean_x*m)

#Predicted values of Y
p=tf.multiply(x,m)
pry=tf.add(p,c)    


#calculating root-mean-square-error
rms=tf.sqrt(tf.reduce_mean(tf.squared_difference(y,pry)))
   
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)
 
print(sess.run(eqn))
print(sess.run(meanx),sess.run(mean_x))
print(sess.run(meany),sess.run(mean_y))

print(sess.run(variance),sess.run(sm))
print(sess.run(covariance),sess.run(cv))

print(sess.run(m_val),sess.run(m))
print(sess.run(c_val),sess.run(c))

print(sess.run(pred),sess.run(pry))
print(sess.run(rms))

plt.plot(sess.run(y),sess.run(pry),label='Actual-Predicted')
plt.legend()
plt.show()

----------------------------------------------------------------------------------
#Lab2 assignment 2
import tensorflow as tf

def tf_train(X_train,y_train, batch_size=20,learning_rate=0.5):
    
    # tf Graph Input
    x = tf.placeholder(tf.float32, [None, 1]) 
    y_ = tf.placeholder(tf.float32, [None, 1])

# Set model weights
    W = tf.Variable(tf.random_normal([1,1],stddev=0.1))
    b = tf.Variable(tf.zeros([10]))
    a = tf.sigmoid(tf.matmul(x,W))
    
# Construct model
    pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax
    #cost = tf.reduce_mean(-(y_*tf.log(a)+(1-y_)*tf.log(1-a)))
    #train_step = tf.train.GradientDescentOptimizer(1e-2).minimize(cost)
# Minimize error using cross entropy
    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))
# Gradient Descent
    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)
    sess = tf.InteractiveSession()
    tf.initialize_all_variables().run()
# Initializing the variables
    #init = tf.global_variables_initializer()
    
    for epoch in range(1000):
        idx = np.random.choice(int(X_train,batch_size)
        #_, l = sess.run([train_step,cost],feed_dict={x:X_train[idx], y_:y_train[idx]})
         _, l = sess.run([train_step, cost], feed_dict={x:X_train[idx], y_:y_train[idx]})
        
        if epoch%100 == 0:
            print("Loss: "+str(l))
            
X=[2.7810836,1.465489372,3.396561688,1.38807019,3.06407232,7.627531214,5.332441248,6.922596716,8.675418651,7.673756466]
y=[2.550537003,2.362125076,4.400293529,1.850220317,3.005305973,2.759262235,2.088626775,1.77106367,-0.2420686551,3.508563011]
tf_train(X,y)
